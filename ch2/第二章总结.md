第二章总结
====================================
## **2.1 视觉SLAM介绍**
对于SLAM技术，有两个任务：
1. 定位   --机器人在什么地方
2. 构图   --周围环境是什么样

视觉SLAM主要是指如何用**相机**解决**定位**和**建图**问题

-----------------------------------------------
## **2.2 经典视觉SLAM框架**
经典视觉SLAM框架如下图所示：
![视觉SLAM框架](https://github.com/xuyuxuan666/SLAM-Learning/blob/main/ch2/资料/图片/视觉SLAM框架.png "视觉SLAM框架" )

我们把视觉SLAM分为5个模块：**传感器**、**前端**、**后端**、**建图**和**回环检测**

视觉SLAM工作流程如下图所示：
![视觉SLAM工作流程](https://github.com/xuyuxuan666/SLAM-Learning/blob/main/ch2/资料/图片/视觉SLAM工作流程.png "视觉SLAM工作流程")

视觉SLAM工作流程介绍：
1. **传感器数据**：相机图像信息的读取和预处理。
2. **视觉里程计**：(Visual Odometry, **VO**)是估算相邻图像间相机的运动，
以及局部地图的样子。VO 又称为**前端**(**Front End**)
3. **后端优化**：(Optimization)后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。又称为后端(**Back end**)
4. **回环检测**：(Loop Closeing)判断机器人是否曾经到达过先前的位置。如果检测到回环，则把信息传递给后端处理。
5. **建图**：(Maping)根据估计的轨迹，完成建图的任务要求。

-----------------------------------------------
## **2.3 数学表述**
SLAM技术的运动方式在数学上的描述是：

机器人在离散时间$t=1,2,3...k-1,k$上的位置变化$x=x_1,x_2,x_3...x_{k-1},x_k$

-----------------------------------------------
## **2.4 开发环境**